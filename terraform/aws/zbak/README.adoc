= DPC Base Cloud Resources

This Terraform project is intended to be the very base account setup, and it will provide the following items ...

* Creates a S3 bucket to hold the Terraform state
* Creates a system property to hold S3 bucket name
* Creates a base role that will be used for GitHub actions
* Creates a GitHub action secret to hold the ARN of the created role so that actions can execute

_This project is critical to everything else in the account(s) as it configures the minimum requirements for everything else to be able to action._

[IMPORTANT]
This Terraform project must be executed in _each_ Aws account that is being used and is currently structured for known Aws Accounts.

== Execute the project

=== Prerequisite for execution

* `aws sso login` - make sure you are authenticated to Aws otherwise you will receive an error
** Note: Terraform can see Aws is logged in via this line `shared_config_files      = ["~/.aws/config"]` in the `provider.tf` file
** Warning: This variant is only used on projects that are not intended to be executed through CI/CD!

=== How to execute for the Tools account

* ensure you are located in `terraform/aws/dpc-base-cloud-resources/account-tools`
* `terraform init` - initialize the project
* `terraform validate` - check that terraform is valid
* `terraform fmt` - make sure terraform is formatted correctly
* `terraform plan` - dry run and review the changes that will be made
* `terraform apply` - if you are good with the changes, apply them
* Answer `yes` - confirm you are good with the changes

=== How to execute for the NP account

* ensure you are located in `terraform/aws/dpc-base-cloud-resources/account-np`
* `terraform init` - initialize the project
* `terraform validate` - check that terraform is valid
* `terraform fmt` - make sure terraform is formatted correctly
* `terraform plan` - dry run and review the changes that will be made
* `terraform apply` - if you are good with the changes, apply them
* Answer `yes` - confirm you are good with the changes

=== How to execute for the Prod account

* ensure you are located in `terraform/aws/dpc-base-cloud-resources/account-prod`
* `terraform init` - initialize the project
* `terraform validate` - check that terraform is valid
* `terraform fmt` - make sure terraform is formatted correctly
* `terraform plan` - dry run and review the changes that will be made
* `terraform apply` - if you are good with the changes, apply them
* Answer `yes` - confirm you are good with the changes



////////
[CAUTION]
THIS PROJECT IS ONLY INTENDED TO BE RAN AGAINST THE "TOOLS" ACCOUNT AND IS NOT STRUCTURED FOR A MULTI-ACCOUNT DEPLOY.

A few important items to be aware of ...

* This project state may not be versioned the same way as others as it is setting up the most basic parts of the account and resources created as part of this may need to be _imported_ into future Terraform projects in the event anything is to ever go wrong with the state of this project. This is also why this project is so minimal that *IF* the resources have to be manually cleaned up, it is not a major challenge.
* S3 bucket name will include a random value to ensure uniqueness as S3 bucket names *MUST* be globally unique.
* The random value generated *WILL NOT* change between Terraform runs (i.e. whatever the random values initial state is the value that will persist until `terraform destroy` is executed in the project)
* If you run `terraform destroy` and there is anything in the bucket, everything will be removed _EXCEPT_ the bucket and its contents.

[WARNING]
Values contained within the `backend` block must be hard coded. Terraform does not support variables within this block.

== Migrating state - Local to Cloud and back again.

In the event this project has been run locally and state is on the local machine this describes how to migrate the `.tfstate` to S3.

=== Migrating state from local to S3

Once this project has been deployed edit and uncomment the `backend` block in `terrafrom.tf`. Next, execute `terraform init -migrate-state` and answer yes. This will migrate the local state to the S3 bucket.

=== Migrate state from S3 to local

If you need to migrate the state from the cloud to your local machine ...

* comment out the entire `backend` block in `terrafrom.tf`
* execute - `terraform init -migrate-state` and answer yes

== Terraform Locking

Terraform now supports version locking natively on S3. Meaning that the creation of a dynamo table is no longer required to facilitate state locking. This is enabled by adding `use_lockfile = true` to the `backend` block.

[NOTE]
What is the purpose of state locking? State locking is to ensure that 2 people working on the same project at the same time do not corrupt the state or cause problems for one another.

== Reference

* https://www.youtube.com/watch?v=AmWnWfuSTfQ
* https://rafaelmedeiros94.medium.com/goodbye-dynamodb-terraform-s3-backend-now-supports-native-locking-06f74037ad39
* https://spacelift.io/blog/terraform-migrate-state
* https://www.google.com/search?client=safari&rls=en&q=terraform+migrate+state+to+s3&ie=UTF-8&oe=UTF-8
* https://medium.com/@deepeshjaiswal6734/setting-up-terraform-with-s3-backend-and-dynamodb-locking-1e4b69e0b3cd

